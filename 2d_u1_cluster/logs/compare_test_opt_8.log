 
>>> PBS_NODEFILE content:
sophia-gpu-01.lab.alcf.anl.gov
1n*1t
Wed Jul  2 19:03:57 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 550.127.05             Driver Version: 550.127.05     CUDA Version: 12.4     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA A100-SXM4-40GB          Off |   00000000:87:00.0 Off |                    0 |
| N/A   25C    P0             50W /  400W |       1MiB /  40960MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   1  NVIDIA A100-SXM4-40GB          Off |   00000000:90:00.0 Off |                    0 |
| N/A   24C    P0             51W /  400W |       1MiB /  40960MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2024 NVIDIA Corporation
Built on Thu_Mar_28_02:18:24_PDT_2024
Cuda compilation tools, release 12.4, V12.4.131
Build cuda_12.4.r12.4/compiler.34097967_0
Start time: 2025-07-02 19:03:57
Python 3.9.18
Python path: /lus/eagle/projects/fthmc/software/ml/bin/python
You are using a CUDA device ('NVIDIA A100-SXM4-40GB') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/2
[W702 19:04:05.115372873 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
----------------------------------------------------------------------------------------------------
distributed_backend=nccl
All distributed processes registered. Starting with 2 processes
----------------------------------------------------------------------------------------------------

============================================================
>>> Arguments:
Lattice size: 64
Number of configurations: 512
Beta: 6.0
Training beta: 4.5
Step size: 0.06
FT step size: 0.05
Max lag: 200
Random seed: 2008
Device: cuda
============================================================
>>> Neural Network Field Transformation HMC Simulation: 
Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/2
[W702 19:04:05.537849092 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
============================================================
>>> Arguments:
Lattice size: 64
Number of configurations: 512
Beta: 6.0
Training beta: 4.5
Step size: 0.06
FT step size: 0.05
Max lag: 200
Random seed: 2008
Device: cuda
============================================================
>>> Neural Network Field Transformation HMC Simulation: 
Trying to use torch.compile for optimized computation...
Successfully initialized torch.compile
>>> Loading trained model
Removing 'module.' prefix from state dict for model 0
Removing 'module.' prefix from state dict for model 1
Removing 'module.' prefix from state dict for model 2
Removing 'module.' prefix from state dict for model 3
Removing 'module.' prefix from state dict for model 4
Removing 'module.' prefix from state dict for model 5
Removing 'module.' prefix from state dict for model 6
Removing 'module.' prefix from state dict for model 7
Loaded best models from epoch 16 with loss 17.788316
>>> Model loaded successfully in 0.06 seconds
Successfully compiled HMC functions with torch.compile
>>> Starting thermalization with field transformation...
>>> Initial thermalization...
Initial thermalization:   0%|          | 0/200 [00:00<?, ?it/s]Successfully compiled HMC functions with torch.compile
>>> Initial thermalization...
Initial thermalization:   0%|          | 0/200 [00:00<?, ?it/s]Initial thermalization:   0%|          | 1/200 [00:47<2:37:46, 47.57s/it]Initial thermalization:   0%|          | 1/200 [00:47<2:37:43, 47.55s/it]Initial thermalization:   1%|          | 2/200 [01:23<2:14:48, 40.85s/it]Initial thermalization:   1%|          | 2/200 [01:23<2:14:58, 40.90s/it]Initial thermalization:   2%|▏         | 3/200 [01:59<2:06:55, 38.66s/it]Initial thermalization:   2%|▏         | 3/200 [01:59<2:07:12, 38.74s/it]Initial thermalization:   2%|▏         | 4/200 [02:36<2:03:11, 37.71s/it]Initial thermalization:   2%|▏         | 4/200 [02:36<2:03:25, 37.79s/it]Initial thermalization:   2%|▎         | 5/200 [03:12<2:00:59, 37.23s/it]Initial thermalization:   2%|▎         | 5/200 [03:12<2:01:18, 37.32s/it]Initial thermalization:   3%|▎         | 6/200 [03:49<1:59:43, 37.03s/it]Initial thermalization:   3%|▎         | 6/200 [03:49<2:00:02, 37.13s/it]W0702 19:08:24.425350 3715423 torch/distributed/elastic/agent/server/api.py:704] Received Signals.SIGTERM death signal, shutting down workers
W0702 19:08:24.427590 3715423 torch/distributed/elastic/multiprocessing/api.py:897] Sending process 3715473 closing signal SIGTERM
W0702 19:08:24.433841 3715423 torch/distributed/elastic/multiprocessing/api.py:897] Sending process 3715474 closing signal SIGTERM
Traceback (most recent call last):
  File "/lus/eagle/projects/fthmc/software/ml/bin/torchrun", line 8, in <module>
    sys.exit(main())
  File "/lus/eagle/projects/fthmc/software/ml/lib64/python3.9/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 355, in wrapper
    return f(*args, **kwargs)
  File "/lus/eagle/projects/fthmc/software/ml/lib64/python3.9/site-packages/torch/distributed/run.py", line 919, in main
    run(args)
  File "/lus/eagle/projects/fthmc/software/ml/lib64/python3.9/site-packages/torch/distributed/run.py", line 910, in run
    elastic_launch(
  File "/lus/eagle/projects/fthmc/software/ml/lib64/python3.9/site-packages/torch/distributed/launcher/api.py", line 138, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/lus/eagle/projects/fthmc/software/ml/lib64/python3.9/site-packages/torch/distributed/launcher/api.py", line 260, in launch_agent
    result = agent.run()
  File "/lus/eagle/projects/fthmc/software/ml/lib64/python3.9/site-packages/torch/distributed/elastic/metrics/api.py", line 137, in wrapper
    result = f(*args, **kwargs)
  File "/lus/eagle/projects/fthmc/software/ml/lib64/python3.9/site-packages/torch/distributed/elastic/agent/server/api.py", line 696, in run
    result = self._invoke_run(role)
  File "/lus/eagle/projects/fthmc/software/ml/lib64/python3.9/site-packages/torch/distributed/elastic/agent/server/api.py", line 855, in _invoke_run
    time.sleep(monitor_interval)
  File "/lus/eagle/projects/fthmc/software/ml/lib64/python3.9/site-packages/torch/distributed/elastic/multiprocessing/api.py", line 84, in _terminate_process_handler
    raise SignalException(f"Process {os.getpid()} got signal: {sigval}", sigval=sigval)
torch.distributed.elastic.multiprocessing.api.SignalException: Process 3715423 got signal: 15
